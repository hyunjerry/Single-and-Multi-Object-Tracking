{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57bb12a1-0549-4360-8e39-7d84b8f8a359",
   "metadata": {},
   "source": [
    "### Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1a2a62-bd6f-4652-bbd7-0e11aa58c087",
   "metadata": {},
   "source": [
    "Alpha-Beta filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1941f929-ffb8-4569-b3ab-394016766f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "def load_obj_each_frame(data_file):\n",
    "    with open(data_file, 'r') as file:\n",
    "        frame_dict = json.load(file)\n",
    "    return frame_dict\n",
    "\n",
    "def alpha_beta_filter(initial_position, initial_velocity, alpha, beta, observations, dt=1):\n",
    "    estimated_position = initial_position\n",
    "    estimated_velocity = initial_velocity\n",
    "    estimates = []\n",
    "\n",
    "    for observation in observations:\n",
    "        # Prediction step\n",
    "        predicted_position = estimated_position + estimated_velocity * dt\n",
    "        predicted_velocity = estimated_velocity\n",
    "\n",
    "        # Update step (if observation is available)\n",
    "        if observation != [-1, -1]:\n",
    "            residual = observation - predicted_position\n",
    "            estimated_position = predicted_position + alpha * residual\n",
    "            estimated_velocity = predicted_velocity + (beta * residual) / dt\n",
    "        else:\n",
    "            # use the prediction if observation is missing\n",
    "            estimated_position = predicted_position\n",
    "            estimated_velocity = predicted_velocity\n",
    "\n",
    "        estimates.append([estimated_position, estimated_velocity])\n",
    "\n",
    "    return estimates\n",
    "\n",
    "def draw_target_object_center(video_file, obj_centers):\n",
    "    count = 0\n",
    "    cap = cv.VideoCapture(video_file)\n",
    "    ok, image = cap.read()\n",
    "\n",
    "    # Initialize Alpha-Beta filter parameters\n",
    "    initial_position = np.array([313, 229])     # Initial guess for position\n",
    "    initial_velocity = np.array([-0.47328952, -0.3911483])  # Initial guess for velocity\n",
    "    alpha = 0.4     # Position update factor\n",
    "    beta = 0.0005   # Velocity update factor\n",
    "    \n",
    "    filtered_estimates = alpha_beta_filter(initial_position, initial_velocity, alpha, beta, obj_centers)\n",
    "\n",
    "    # Save in a JSON file\n",
    "    estimated_positions = [x[0] for x in filtered_estimates]\n",
    "    part_1_object_tracking = [[int(round(x)), int(round(y))] for x, y in estimated_positions]\n",
    "    print(len(part_1_object_tracking))\n",
    "    output_data = {\"obj\": part_1_object_tracking}\n",
    "    # with open('part_1_object_tracking.json', 'w', encoding='utf-8') as file:\n",
    "    #     json.dump(output_data, file, ensure_ascii=False, indent=None)\n",
    "    # print(\"Successfully saved in part_1_object_tracking.json!\")\n",
    "    with open('part_1_object_tracking_with_ab.json', 'w', encoding='utf-8') as file:\n",
    "        json.dump(output_data, file, ensure_ascii=False, indent=None)\n",
    "    print(\"Successfully saved in part_1_object_tracking_with_ab.json!\")\n",
    "\n",
    "    # Visualize the smoothed track\n",
    "    # vidwrite = cv.VideoWriter(\"part_1_demo.mp4\", cv.VideoWriter_fourcc(*'MP4V'), 30, (700,500))\n",
    "    vidwrite = cv.VideoWriter(\"part_1_demo_with_ab.mp4\", cv.VideoWriter_fourcc(*'MP4V'), 30, (700,500))\n",
    "    while ok:\n",
    "        if count < len(filtered_estimates):\n",
    "            pos, _ = filtered_estimates[count]\n",
    "            pos_x, pos_y = pos\n",
    "        else:\n",
    "            break\n",
    "\n",
    "        count += 1\n",
    "        ###### !!! #######\n",
    "        # Make sure the video is resized. Otherwise the coords in the data file won't work.\n",
    "        image = cv.resize(image, (700, 500)) \n",
    "        ###### !!! #######\n",
    "        # Draw the circle at the estimated position\n",
    "        # if pos_x != -1 and pos_y != -1:\n",
    "        #     image = cv.circle(image, (int(pos_x), int(pos_y)), 1, (0, 0, 255), 2)\n",
    "        # Draw the Line\n",
    "        for i in range(count):\n",
    "            pos, _ = filtered_estimates[i]\n",
    "            pos_x, pos_y = pos\n",
    "            image = cv.circle(image, (int(pos_x), int(pos_y)), 1, (0, 0, 255), 2)\n",
    "        vidwrite.write(image)\n",
    "        \n",
    "        ok, image = cap.read()\n",
    "\n",
    "    vidwrite.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fbcf7ce-eadc-4021-90a9-de052629ee32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249\n",
      "Successfully saved in part_1_object_tracking_with_ab.json!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    }
   ],
   "source": [
    "frame_dict = load_obj_each_frame(\"object_to_track.json\")\n",
    "video_file = \"commonwealth.mp4\"\n",
    "draw_target_object_center(video_file,frame_dict['obj'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42715757-2b0f-4475-b41e-cbb45e410792",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "Kalman filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1dd7cc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "def load_obj_each_frame(data_file):\n",
    "    with open(data_file, 'r') as file:\n",
    "        frame_dict = json.load(file)\n",
    "    return frame_dict\n",
    "\n",
    "def kalman_filter(initial_state, initial_covariance, transition_matrix, observation_matrix, process_noise, measurement_noise, observations):\n",
    "    state_estimate = initial_state\n",
    "    covariance_estimate = initial_covariance\n",
    "    estimates = []\n",
    "\n",
    "    for observation in observations:\n",
    "        # Prediction step\n",
    "        predicted_state = transition_matrix @ state_estimate\n",
    "        predicted_covariance = transition_matrix @ covariance_estimate @ transition_matrix.T + process_noise\n",
    "\n",
    "        # Update step\n",
    "        if observation != [-1, -1]:\n",
    "            observation = np.array(observation)\n",
    "            innovation = observation - (observation_matrix @ predicted_state)\n",
    "            innovation_covariance = observation_matrix @ predicted_covariance @ observation_matrix.T + measurement_noise\n",
    "\n",
    "            kalman_gain = predicted_covariance @ observation_matrix.T @ np.linalg.inv(innovation_covariance)\n",
    "\n",
    "            state_estimate = predicted_state + kalman_gain @ innovation\n",
    "            covariance_estimate = (np.eye(len(initial_state)) - kalman_gain @ observation_matrix) @ predicted_covariance\n",
    "        else:\n",
    "            # skip this step if observation is missing\n",
    "            state_estimate = predicted_state\n",
    "            covariance_estimate = predicted_covariance\n",
    "\n",
    "        estimates.append(state_estimate.tolist())\n",
    "\n",
    "    return estimates\n",
    "\n",
    "def draw_target_object_center(video_file, obj_centers):\n",
    "    count = 0\n",
    "    cap = cv.VideoCapture(video_file)\n",
    "    ok, image = cap.read()\n",
    "\n",
    "    # https://www.bzarg.com/p/how-a-kalman-filter-works-in-pictures/\n",
    "    # Initialize Kalman filter parameters\n",
    "    # The result from the alpha-beta filter looks good, and the car seems to be moving at a constant speed, so B is not necessary.\n",
    "    initial_state = np.array([313, 229, -0.5, -0.4])   # X\n",
    "    initial_covariance = np.eye(4)  # naive P\n",
    "    transition_matrix = np.array([[1, 0, 1, 0], [0, 1, 0, 1], [0, 0, 1, 0], [0, 0, 0, 1]])  # A, assume dt=1\n",
    "    observation_matrix = np.array([[1, 0, 0, 0], [0, 1, 0, 0]])     # H\n",
    "    process_noise = np.eye(4) * (1**2)     # Q\n",
    "    measurement_noise = np.eye(2) * (120**2)    # R\n",
    "    \n",
    "    filtered_estimates = kalman_filter(initial_state, initial_covariance, transition_matrix, observation_matrix, process_noise, measurement_noise, obj_centers)\n",
    "\n",
    "    # print([row[0] for row in filtered_estimates])\n",
    "    # print([row[1] for row in filtered_estimates])\n",
    "    \n",
    "    # Save in a JSON file\n",
    "    estimated_positions = [[row[0], row[1]] for row in filtered_estimates]\n",
    "    part_1_object_tracking = [[int(round(x)), int(round(y))] for x, y in estimated_positions]\n",
    "    print(len(part_1_object_tracking))\n",
    "    output_data = {\"obj\": part_1_object_tracking}\n",
    "    with open('part_1_object_tracking.json', 'w', encoding='utf-8') as file:\n",
    "        json.dump(output_data, file, ensure_ascii=False, indent=None)\n",
    "    print(\"Successfully saved in part_1_object_tracking.json!\")\n",
    "    # with open('part_1_object_tracking_with_kalman.json', 'w', encoding='utf-8') as file:\n",
    "    #     json.dump(output_data, file, ensure_ascii=False, indent=None)\n",
    "    # print(\"Successfully saved in part_1_object_tracking_with_kalman.json!\")\n",
    "\n",
    "    # Visualize the smoothed track\n",
    "    vidwrite = cv.VideoWriter(\"part_1_demo.mp4\", cv.VideoWriter_fourcc(*'MP4V'), 30, (700,500))\n",
    "    # vidwrite = cv.VideoWriter(\"part_1_demo_with_kalman.mp4\", cv.VideoWriter_fourcc(*'MP4V'), 30, (700,500))\n",
    "    while ok:\n",
    "        if count < len(filtered_estimates):\n",
    "            pos_x, pos_y, _, _ = filtered_estimates[count]\n",
    "        else:\n",
    "            break\n",
    "\n",
    "        count += 1\n",
    "        ###### !!! #######\n",
    "        # Make sure the video is resized. Otherwise the coords in the data file won't work.\n",
    "        image = cv.resize(image, (700, 500)) \n",
    "        ###### !!! #######\n",
    "        # Draw the circle at the estimated position\n",
    "        # if pos_x != -1 and pos_y != -1:\n",
    "        #     image = cv.circle(image, (int(pos_x), int(pos_y)), 1, (0, 0, 255), 2)\n",
    "        # Draw the Line\n",
    "        for i in range(count):\n",
    "            pos_x, pos_y, _, _ = filtered_estimates[i]\n",
    "            image = cv.circle(image, (int(pos_x), int(pos_y)), 1, (0, 0, 255), 2)\n",
    "        vidwrite.write(image)\n",
    "        \n",
    "        ok, image = cap.read()\n",
    "\n",
    "    vidwrite.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "acfd46de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249\n",
      "Successfully saved in part_1_object_tracking.json!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    }
   ],
   "source": [
    "frame_dict = load_obj_each_frame(\"object_to_track.json\")\n",
    "video_file = \"commonwealth.mp4\"\n",
    "draw_target_object_center(video_file,frame_dict['obj'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
